#!/usr/bin/env perl
use strict;
use warnings;
use Cwd qw(getcwd);
use FindBin;
use lib $FindBin::RealBin;
use File::Path qw(make_path);
use File::Spec;
use Getopt::Long;
use Pod::Usage;
use POSIX qw(:sys_wait_h ceil floor);
use File::Basename;
use Log::Log4perl qw(:easy);
use Parallel::ForkManager;

# Configure logging
Log::Log4perl->easy_init({
    level   => $INFO,
    layout  => '[%d] %p %m%n',
    file    => '>>' . getcwd() . '/build_rs.log'
});
my $logger = Log::Log4perl->get_logger();

our $VERSION = '1.0.0';

# Program Configuration
my %config = (
    tmp_dir => undef,
    genome_file => undef,
    threads => 4,
    sample_size => 'all',
    rmblast_dir => undef,
    work_dir => undef
);

# Parse and validate arguments
get_and_validate_args();

# Set up environment
$logger->info("Setting up environment...");
setup_environment();

# Main execution flow
run_pipeline();

exit(0);

sub get_and_validate_args {
    GetOptions(
        'help|h'        => \my $help,
        'version|v'     => \my $version,
        'tmp=s'         => \$config{tmp_dir},
        'genome=s'      => \$config{genome_file},
        'threads=i'     => \$config{threads},
        'sample=s'      => \$config{sample_size},
        'workdir=s'     => \$config{work_dir}
    ) or pod2usage(2);

    pod2usage(1) if $help;
    if ($version) {
        print "build_RS version $VERSION\n";
        exit(0);
    }

    # Try to locate rmblast directory through multiple methods
    $config{rmblast_dir} = $ENV{RMBLAST_DIR};
    unless ($config{rmblast_dir}) {
        eval {
            use RepModelConfig;
            $config{rmblast_dir} = $RepModelConfig::configuration->{'RMBLAST_DIR'}->{'value'};
        };
    }

    # If still not found, try locating rmblastn
    unless ($config{rmblast_dir} && -x "$config{rmblast_dir}/rmblastn") {
        $config{rmblast_dir} = locate_rmblastn();
    }

    my @required = qw(tmp_dir genome_file work_dir); 
    for my $req (@required) {
        unless (defined $config{$req}) {
            $logger->error("Missing required parameter: --$req");
            die "Error: --$req is required\n";
        }
    }

    unless ($config{rmblast_dir}) {
        $logger->error("RMBLAST_DIR environment variable or configuration not found");
        die "Error: RMBLAST_DIR must be set in environment or configuration\n";
    }

    # Log configuration
    $logger->info("Configuration:");
    $logger->info("  Genome file: $config{genome_file}");
    $logger->info("  Threads: $config{threads}");
    $logger->info("  Working directory: $config{work_dir}");
    $logger->info("  RMBlast directory: $config{rmblast_dir}");
}

sub locate_rmblastn {
    $logger->info("Attempting to locate rmblastn...");
    
    # Try whereis command
    my $whereis_out = `whereis rmblastn`;
    if ($whereis_out =~ /rmblastn:\s+(\S+)/) {
        my $path = $1;
        if (-x $path) {
            $logger->info("Found rmblastn via whereis: $path");
            return dirname($path);
        }
    }
    
    # Try find command in common locations
    for my $base_dir ("/usr/local", "/usr", $ENV{HOME}, "/opt") {
        my $cmd = "find $base_dir -name rmblastn -type f 2>/dev/null";
        my $find_out = `$cmd`;
        if ($find_out) {
            chomp($find_out);
            my @paths = split(/\n/, $find_out);
            foreach my $path (@paths) {
                if (-x $path) {
                    $logger->info("Found rmblastn via find: $path");
                    return dirname($path);
                }
            }
        }
    }
    
    $logger->error("Could not locate rmblastn executable");
    die "Error: rmblastn not found in system\n";
}

sub setup_environment {
    # Create necessary directories
    for my $dir ($config{tmp_dir}, $config{work_dir}) {
        unless (-d $dir) {
            $logger->info("Creating directory: $dir");
            make_path($dir) or die "Failed to create directory $dir: $!\n";
        }
    }

    # Change to work directory
    chdir $config{work_dir} or die "Cannot change to work directory: $!\n";
    $logger->info("Changed to working directory: " . getcwd());
}

sub run_pipeline {
    $logger->info("Starting RepeatScout pipeline...");

    # Get genome size and calculate parameters
    my $genome_size = -s $config{genome_file};
    my $readable_size = sprintf("%.2f", $genome_size/1e9) . " Gb";
    $logger->info("Processing genome of size: $readable_size");

    # Calculate sampling strategy based on genome size thresholds
    my ($sample_strategy, $sample_size, $chunk_size, $num_chunks) = 
        determine_sampling_strategy($genome_size);
    
    $logger->info("Sampling strategy: $sample_strategy");
    if ($sample_strategy eq "sample_parallel") {
        $logger->info("Sample size per chunk: " . sprintf("%.2f", $sample_size/1e6) . " Mb");
        $logger->info("Total sampling: " . sprintf("%.2f", ($sample_size * $num_chunks)/1e6) . " Mb");
    } else {
        $logger->info("Sample size: " . sprintf("%.2f", $sample_size/1e6) . " Mb");
    }
    $logger->info("Chunk size: " . sprintf("%.2f", $chunk_size/1e3) . " Kb");
    $logger->info("Number of parallel chunks: $num_chunks");

    my $lmer_size = calculate_lmer_size($genome_size);
    $logger->info("Calculated l-mer size: $lmer_size");

    # Check for RepeatScout results
    my $rs_consensus = "$config{tmp_dir}/repeats.fa";
    my $filtered_consensus = "$config{tmp_dir}/repeats.filtered.fa";

    if (-s $filtered_consensus) {
        $logger->info("Found existing filtered consensus sequences, skipping to refinement...");
        refine_consensus();
    }
    elsif (-s $rs_consensus) {
        $logger->info("Found existing RepeatScout results, skipping to filtering...");
        filter_repeats();
        refine_consensus();
    }
    else {
        # Run complete pipeline
        eval {
            # Process genome based on sampling strategy
            if ($sample_strategy eq "sample_parallel" && $num_chunks > 1) {
                run_parallel_repeatscout($sample_strategy, $sample_size, $chunk_size, $num_chunks, $lmer_size);
            } else {
                # Single run processing
                process_genome_by_strategy($sample_strategy, $num_chunks, $chunk_size);
                run_build_lmer_table($lmer_size);
                run_repeat_scout($lmer_size);
            }
            filter_repeats();
            refine_consensus();
        };
        if ($@) {
            $logger->error("Pipeline failed: $@");
            die "Pipeline execution failed\n";
        }
    }

    $logger->info("Pipeline completed successfully");
}

sub calculate_lmer_size {
    my ($genome_size) = @_;
    return ceil(log($genome_size)/log(4) + 1);
}

sub run_build_lmer_table {
    my ($lmer_size) = @_;
    my $freq_file = "$config{tmp_dir}/lmer.freq";

    $logger->info("Building l-mer frequency table (l=$lmer_size)...");
    
    my $cmd = join(" ",
        "build_lmer_table",
        "-l $lmer_size",
        "-sequence $config{tmp_dir}/tmp.fa",
        "-freq $freq_file",
        "2> $config{tmp_dir}/build_lmer.log"
    );

    run_cmd($cmd);
    $logger->info("L-mer table building completed");
}

sub run_repeat_scout {
    my ($lmer_size) = @_;
    my $freq_file = "$config{tmp_dir}/lmer.freq";
    my $output = "$config{tmp_dir}/repeats.fa";

    $logger->info("Running RepeatScout...");

    my $cmd = join(" ",
        "RepeatScout",
        "-sequence $config{tmp_dir}/tmp.fa",
        "-output $output",
        "-freq $freq_file",
        "-l $lmer_size",
        "-tandemdist 50",
        "-minthresh 3",
        "2>> $config{tmp_dir}/repeatscout.log"
    );

    run_cmd($cmd);
    $logger->info("RepeatScout processing completed");
}

sub filter_repeats {
    $logger->info("Filtering repeat sequences...");

    my $input = "$config{tmp_dir}/repeats.fa";
    my $output = "$config{tmp_dir}/repeats.filtered.fa";

    $ENV{TRF_COMMAND} = which('trf');
    $ENV{RMBLAST_DIR} = $config{rmblast_dir};

    system("filter-stage-1.prl $input > $output 2> $config{tmp_dir}/filter.log") == 0
    	or die "Failed to run filter-stage-1.prl: $?\n";
    $logger->info("Repeat filtering completed");
}

sub refine_consensus {
    $logger->info("Refining consensus sequences...");

    my $input = "$config{tmp_dir}/repeats.filtered.fa";
    my $output_dir = "$config{work_dir}/refiner_output";
    my $final_output = "$config{work_dir}/consensi.fa";

    # Create required directories
    make_path($config{work_dir}) unless -d $config{work_dir};
    make_path($output_dir) unless -d $output_dir;
    
    # Ensure all input files exist
    die "Input file missing: $input\n" unless -f $input;
    
    # Determine genome input for Refiner based on sampling strategy
    my $refiner_genome = determine_refiner_genome_input();
    
    # Use the new Refiner pipeline
    my $cmd = join(" ",
        "python3", "$FindBin::RealBin/Refiner/main.py",
        '--repeatscout', $input,              # RepeatScout filtered output
        '--genome', $refiner_genome,          # Reference genome for Refiner
        '--output', $output_dir,              # Output directory for Refiner
        '--threads', $config{threads},        # Number of threads
        '--keep-temp',                        # Keep temporary files for debugging
        '2>', "$config{tmp_dir}/refiner.log"  # Log file
    );

    $logger->info("Running advanced TE consensus building with command: $cmd");
    system($cmd) == 0 
        or do {
            $logger->error("Advanced consensus refinement failed with status: $?");
            die "Advanced consensus refinement failed\n";
        };
    
    # Check for the main output file from Refiner and copy it to expected location
    my $refiner_consensus = "$output_dir/consensus_masking.fa";
    if (-f $refiner_consensus) {
        $logger->info("Copying refined consensus from $refiner_consensus to $final_output");
        system("cp '$refiner_consensus' '$final_output'") == 0
            or do {
                $logger->error("Failed to copy consensus file");
                die "Failed to copy consensus file\n";
            };
    } else {
        $logger->error("Refiner output file not found: $refiner_consensus");
        die "Refiner output file not found\n";
    }
    
    $logger->info("Advanced consensus refinement completed successfully");
}

sub determine_refiner_genome_input {
    my $genome_size = -s $config{genome_file};
    my $gb_1_2 = 1.2 * 1024 * 1024 * 1024;  # 1.2GB
    
    if ($genome_size < $gb_1_2) {
        # Small genome (<1.2Gb): use single sample
        $logger->info("Using single sample for Refiner input (genome < 1.2Gb)");
        return create_refiner_sample(500 * 1024 * 1024, 1);
    } else {
        # Large genome (>=1.2Gb): merge 2 samples
        $logger->info("Using merged samples for Refiner input (genome >= 1.2Gb)");
        return create_refiner_sample(500 * 1024 * 1024, 2);
    }
}

sub create_refiner_sample {
    my ($sample_size, $num_samples) = @_;
    
    my $refiner_genome = "$config{tmp_dir}/refiner_genome.fa";
    
    # Create index if needed
    unless (-f "$config{genome_file}.fai") {
        run_cmd("samtools faidx $config{genome_file}");
    }
    
    if ($num_samples == 1) {
        # Single sample
        my $chunk_size = 40 * 1024;  # 40KB chunks for better representation
        my $num_chunks = int($sample_size / $chunk_size);
        sample_random_chunks($config{genome_file}, $num_chunks, $chunk_size, $refiner_genome);
    } else {
        # Multiple samples - merge them
        my @temp_files;
        my $chunk_size = 40 * 1024;  # 40KB chunks
        my $num_chunks_per_sample = int($sample_size / $chunk_size);
        
        for my $i (1..$num_samples) {
            my $temp_file = "$config{tmp_dir}/refiner_sample_$i.fa";
            sample_random_chunks($config{genome_file}, $num_chunks_per_sample, $chunk_size, $temp_file);
            push @temp_files, $temp_file;
        }
        
        # Merge all samples
        my $cat_cmd = "cat " . join(" ", @temp_files) . " > $refiner_genome";
        run_cmd($cat_cmd);
        
        # Clean up temp files
        unlink @temp_files;
    }
    
    $logger->info("Created Refiner genome input: $refiner_genome");
    return $refiner_genome;
}

sub which {
    my ($program) = @_;
    for my $path (split /:/, $ENV{PATH}) {
        my $file = "$path/$program";
        return $file if -x $file;
    }
    $logger->error("Cannot find $program in PATH");
    die "Cannot find $program in PATH\n";
}

sub determine_sampling_strategy {
    my ($genome_size) = @_;
    
    my $mb_500 = 500 * 1024 * 1024;    # 500MB
    my $gb_1 = 1024 * 1024 * 1024;     # 1GB
    my $gb_3 = 3 * 1024 * 1024 * 1024; # 3GB
    my $gb_5 = 5 * 1024 * 1024 * 1024; # 5GB
    
    if ($genome_size < $mb_500) {
        # Small genome (<500Mb): fragment into 30Kb pieces
        my $strategy = "fragment_all";
        my $chunk_size = 30 * 1024;  # 30KB
        my $num_chunks = 1;  # Single run
        return ($strategy, $genome_size, $chunk_size, $num_chunks);
    }
    elsif ($genome_size >= $mb_500 && $genome_size < $gb_1) {
        # Medium genome (500Mb-1Gb): sample 500Mb in 30Kb chunks
        my $strategy = "sample_single";
        my $sample_size = 500 * 1024 * 1024;  # 500MB
        my $chunk_size = 30 * 1024;  # 30KB
        my $num_chunks = 1;  # Single run
        return ($strategy, $sample_size, $chunk_size, $num_chunks);
    }
    elsif ($genome_size >= $gb_1 && $genome_size < $gb_3) {
        # Large genome (1Gb-3Gb): sample 2×500Mb in 40Kb chunks
        my $strategy = "sample_parallel";
        my $sample_size = 500 * 1024 * 1024;  # 500MB per chunk
        my $chunk_size = 40 * 1024;  # 40KB
        my $num_chunks = 2;  # Two parallel runs
        return ($strategy, $sample_size, $chunk_size, $num_chunks);
    }
    elsif ($genome_size >= $gb_3 && $genome_size < $gb_5) {
        # Very large genome (3Gb-5Gb): sample 3×500Mb in 50Kb chunks
        my $strategy = "sample_parallel";
        my $sample_size = 500 * 1024 * 1024;  # 500MB per chunk
        my $chunk_size = 50 * 1024;  # 50KB
        my $num_chunks = 3;  # Three parallel runs
        return ($strategy, $sample_size, $chunk_size, $num_chunks);
    }
    else {
        # Massive genome (>5Gb): sample 4×500Mb in 50Kb chunks
        my $strategy = "sample_parallel";
        my $sample_size = 500 * 1024 * 1024;  # 500MB per chunk
        my $chunk_size = 50 * 1024;  # 50KB
        my $num_chunks = 4;  # Four parallel runs
        return ($strategy, $sample_size, $chunk_size, $num_chunks);
    }
}

sub process_genome_by_strategy {
    my ($strategy, $num_chunks, $chunk_size) = @_;
    
    $logger->info("Processing genome with strategy: $strategy");
    
    if ($strategy eq "fragment_all") {
        fragment_entire_genome($chunk_size);
    }
    elsif ($strategy eq "sample_single") {
        # Single sampling run
        my $sample_size = 500 * 1024 * 1024;  # 500MB
        my $num_samples = $sample_size / $chunk_size;
        sample_genome_chunks($num_samples, $chunk_size);
    }
    else {
        die "Unknown single sampling strategy: $strategy\n";
    }
}

sub fragment_entire_genome {
    my ($fragment_size) = @_;
    
    $logger->info("Fragmenting entire genome into ${fragment_size}bp pieces...");
    
    # For small genomes, we should just copy the whole genome
    # since fragmenting sequences shorter than fragment_size would result in empty output
    my $genome_size = -s $config{genome_file};
    
    if ($genome_size < $fragment_size) {
        # If genome is smaller than fragment size, just copy it as is
        $logger->info("Genome smaller than fragment size, using entire genome");
        my $cmd = "cp $config{genome_file} $config{tmp_dir}/tmp.fa";
        run_cmd($cmd);
    } else {
        # Use seqkit sliding with step size = 1/10 of window to ensure coverage
        # This creates overlapping fragments for better repeat detection
        my $step_size = int($fragment_size / 10);
        $step_size = $step_size > 0 ? $step_size : 1;
        
        my $cmd = join(" ",
            "seqkit sliding",
            "-s $step_size",           # Step size for overlap
            "-W $fragment_size",       # Window size = fragment size
            "-g",                      # Remove gap characters in sequences
            "$config{genome_file}",
            "> $config{tmp_dir}/tmp.fa"
        );
        
        run_cmd($cmd);
    }
    
    $logger->info("Genome fragmentation completed");
}

sub sample_genome_chunks {
    my ($num_samples, $chunk_size) = @_;
    
    $logger->info("Sampling $num_samples chunks of ${chunk_size}bp from genome...");
    
    # First create an index if it doesn't exist
    unless (-f "$config{genome_file}.fai") {
        run_cmd("samtools faidx $config{genome_file}");
    }
    
    # Use custom sampling function
    sample_random_chunks($config{genome_file}, $num_samples, $chunk_size, "$config{tmp_dir}/tmp.fa");
    
    $logger->info("Random chunk sampling completed");
}

sub run_parallel_repeatscout {
    my ($strategy, $sample_size_per_chunk, $chunk_size, $num_chunks, $lmer_size) = @_;
    
    $logger->info("Running parallel RepeatScout with $num_chunks chunks...");
    
    # Create index if needed
    unless (-f "$config{genome_file}.fai") {
        run_cmd("samtools faidx $config{genome_file}");
    }
    
    # Create parallel work directories
    my @chunk_dirs;
    for my $i (1..$num_chunks) {
        my $chunk_dir = "$config{tmp_dir}/chunk_$i";
        make_path($chunk_dir) unless -d $chunk_dir;
        push @chunk_dirs, $chunk_dir;
    }
    
    # Generate sampling for each chunk
    my $num_samples_per_chunk = int($sample_size_per_chunk / $chunk_size);
    for my $i (1..$num_chunks) {
        my $chunk_dir = $chunk_dirs[$i-1];
        my $chunk_fa = "$chunk_dir/chunk.fa";
        
        $logger->info("Generating chunk $i: $num_samples_per_chunk samples of ${chunk_size}bp");
        sample_random_chunks($config{genome_file}, $num_samples_per_chunk, $chunk_size, $chunk_fa);
    }
    
    # Run RepeatScout in parallel using fork
    use Parallel::ForkManager;
    my $pm = Parallel::ForkManager->new($num_chunks);
    
    my @results;
    $pm->run_on_finish(sub {
        my ($pid, $exit_code, $ident, $exit_signal, $core_dump, $data_ref) = @_;
        if ($data_ref) {
            push @results, $data_ref;
        }
    });
    
    # Fork and run RepeatScout for each chunk
    for my $i (1..$num_chunks) {
        my $chunk_dir = $chunk_dirs[$i-1];
        
        $pm->start and next;  # Fork
        
        # Child process
        eval {
            my $chunk_fa = "$chunk_dir/chunk.fa";
            my $freq_file = "$chunk_dir/lmer.freq";
            my $repeats_file = "$chunk_dir/repeats.fa";
            my $filtered_file = "$chunk_dir/repeats.filtered.fa";
            
            # Build lmer table for this chunk
            $logger->info("Building lmer table for chunk $i...");
            my $cmd = "build_lmer_table -l $lmer_size -sequence $chunk_fa -freq $freq_file 2> $chunk_dir/build_lmer.log";
            system($cmd) == 0 or die "Failed to build lmer table for chunk $i: $?\n";
            
            # Run RepeatScout for this chunk
            $logger->info("Running RepeatScout for chunk $i...");
            $cmd = "RepeatScout -sequence $chunk_fa -output $repeats_file -freq $freq_file -l $lmer_size -tandemdist 50 -minthresh 3 2> $chunk_dir/repeatscout.log";
            system($cmd) == 0 or die "Failed to run RepeatScout for chunk $i: $?\n";
            
            # Filter results for this chunk
            $logger->info("Filtering repeats for chunk $i...");
            $ENV{TRF_COMMAND} = which('trf');
            $ENV{RMBLAST_DIR} = $config{rmblast_dir};
            system("filter-stage-1.prl $repeats_file > $filtered_file 2> $chunk_dir/filter.log") == 0
                or die "Failed to filter repeats for chunk $i: $?\n";
            
            $logger->info("Chunk $i completed successfully");
        };
        
        if ($@) {
            $logger->error("Chunk $i failed: $@");
            $pm->finish(1);  # Exit child with error
        } else {
            $pm->finish(0);  # Exit child successfully
        }
    }
    
    $pm->wait_all_children;
    
    # Merge results from all chunks
    $logger->info("Merging results from $num_chunks chunks...");
    merge_parallel_results(\@chunk_dirs);
    
    $logger->info("Parallel RepeatScout processing completed");
}

sub merge_parallel_results {
    my ($chunk_dirs) = @_;
    
    my $merged_file = "$config{tmp_dir}/repeats.filtered.fa";
    my $temp_merge = "$config{tmp_dir}/temp_merged.fa";
    
    # Collect all filtered results
    my @filtered_files;
    for my $chunk_dir (@$chunk_dirs) {
        my $filtered_file = "$chunk_dir/repeats.filtered.fa";
        if (-s $filtered_file) {
            push @filtered_files, $filtered_file;
        } else {
            $logger->warn("No filtered results found in $chunk_dir");
        }
    }
    
    die "No filtered results found from any chunk\n" unless @filtered_files;
    
    # Simple concatenation first
    $logger->info("Concatenating results from " . scalar(@filtered_files) . " chunks...");
    my $cat_cmd = "cat " . join(" ", @filtered_files) . " > $temp_merge";
    run_cmd($cat_cmd);
    
    # Apply simple validation: keep sequences that appear in multiple chunks or are >2kb
    $logger->info("Applying cross-validation and length filtering...");
    validate_and_merge_sequences($temp_merge, $merged_file);
    
    # Clean up temp file
    unlink $temp_merge;
    
    $logger->info("Results merging completed");
}

sub validate_and_merge_sequences {
    my ($input_file, $output_file) = @_;
    
    # Read all sequences and count occurrences
    my %seq_count;
    my %seq_data;
    
    open(my $in_fh, '<', $input_file) or die "Cannot read $input_file: $!\n";
    my $current_id;
    my $current_seq = "";
    
    while (my $line = <$in_fh>) {
        chomp $line;
        if ($line =~ /^>(.+)/) {
            # Process previous sequence
            if ($current_id && $current_seq) {
                my $seq_key = uc($current_seq);
                $seq_count{$seq_key}++;
                $seq_data{$seq_key} = {id => $current_id, seq => $current_seq};
            }
            # Start new sequence
            $current_id = $1;
            $current_seq = "";
        } else {
            $current_seq .= $line;
        }
    }
    
    # Process last sequence
    if ($current_id && $current_seq) {
        my $seq_key = uc($current_seq);
        $seq_count{$seq_key}++;
        $seq_data{$seq_key} = {id => $current_id, seq => $current_seq};
    }
    close($in_fh);
    
    # Write validated sequences
    open(my $out_fh, '>', $output_file) or die "Cannot create $output_file: $!\n";
    
    my $kept_count = 0;
    my $total_count = scalar(keys %seq_data);
    
    for my $seq_key (keys %seq_data) {
        my $count = $seq_count{$seq_key};
        my $length = length($seq_key);
        
        # Keep sequence if:
        # 1. Found in multiple chunks (count > 1), OR
        # 2. Length > 2000bp (likely real repeat)
        if ($count > 1 || $length > 2000) {
            my $data = $seq_data{$seq_key};
            print $out_fh ">$data->{id}_validated_c${count}_l${length}\n";
            print $out_fh "$data->{seq}\n";
            $kept_count++;
        }
    }
    
    close($out_fh);
    
    $logger->info("Validation complete: kept $kept_count / $total_count sequences");
}

sub sample_random_chunks {
    my ($genome_file, $num_samples, $chunk_size, $output_file) = @_;
    
    # Read genome index to get sequence information
    my @sequences;
    open(my $fai_fh, '<', "$genome_file.fai") or die "Cannot read fai file: $!\n";
    while (my $line = <$fai_fh>) {
        chomp $line;
        my ($seq_name, $length) = split(/\t/, $line);
        # Include all sequences, even those shorter than chunk size
        push @sequences, {name => $seq_name, length => $length};
    }
    close($fai_fh);
    
    die "No sequences long enough for sampling\n" unless @sequences;
    
    # Calculate total available length
    my $total_length = 0;
    for my $seq (@sequences) {
        if ($seq->{length} >= $chunk_size) {
            $total_length += $seq->{length} - $chunk_size + 1;  # Available positions for sampling
        } else {
            $total_length += 1;  # Can use the whole sequence as one sample
        }
    }
    
    $logger->info("Total sequences: " . scalar(@sequences));
    $logger->info("Total available positions: $total_length");
    
    # Generate random sampling positions
    my @samples;
    my $attempts = 0;
    my $max_attempts = $num_samples * 10;
    
    while (@samples < $num_samples && $attempts < $max_attempts) {
        $attempts++;
        
        # Randomly select a sequence weighted by length
        my $rand_pos = int(rand($total_length));
        my $cumulative = 0;
        my $selected_seq;
        
        for my $seq (@sequences) {
            my $available_positions;
            if ($seq->{length} >= $chunk_size) {
                $available_positions = $seq->{length} - $chunk_size + 1;
            } else {
                $available_positions = 1;  # Can only take the whole sequence
            }
            $cumulative += $available_positions;
            if ($rand_pos < $cumulative) {
                $selected_seq = $seq;
                last;
            }
        }
        
        next unless $selected_seq;
        
        # Handle position selection based on sequence length
        my ($start_pos, $end_pos);
        if ($selected_seq->{length} >= $chunk_size) {
            # Random position within selected sequence
            my $max_start = $selected_seq->{length} - $chunk_size;
            $start_pos = int(rand($max_start)) + 1;  # 1-based coordinates
            $end_pos = $start_pos + $chunk_size - 1;
        } else {
            # For sequences shorter than chunk size, take the whole sequence
            $start_pos = 1;
            $end_pos = $selected_seq->{length};
        }
        
        # Create sample entry
        my $sample_id = sprintf("sample_%04d_%s_%d_%d", 
                               scalar(@samples), $selected_seq->{name}, $start_pos, $end_pos);
        
        push @samples, {
            id => $sample_id,
            seq => $selected_seq->{name},
            start => $start_pos,
            end => $end_pos
        };
        
        if (@samples % 500 == 0) {
            $logger->info("Generated " . scalar(@samples) . " / $num_samples samples");
        }
    }
    
    $logger->info("Generated " . scalar(@samples) . " samples total");
    
    # Extract sequences using samtools faidx
    open(my $out_fh, '>', $output_file) or die "Cannot create output file: $!\n";
    
    for my $sample (@samples) {
        my $region = "$sample->{seq}:$sample->{start}-$sample->{end}";
        my $seq_data = `samtools faidx $genome_file $region`;
        
        if ($seq_data) {
            # Replace header with our sample ID
            $seq_data =~ s/^>[^\n]+/>$sample->{id}/;
            print $out_fh $seq_data;
        }
    }
    
    close($out_fh);
    $logger->info("Sequence extraction completed");
}

sub run_cmd {
    my $cmd = shift;
    $cmd =~ s/[`;\$]/\\$&/g;
    $logger->info("Executing command: $cmd");
    
    my $output = `$cmd 2>&1`;
    my $exit_code = $? >> 8;
    
    if ($exit_code != 0) {
        $logger->error("Command failed with exit code: $exit_code");
        $logger->error("Command output:");
        $logger->error($output);
        die "Command execution failed\n";
    }
    
    $logger->debug("Command completed successfully");
    return $output;
}

