"""
Phase 4: 高质量基因组Masking
两步策略：
1. 使用Phase 1的高可信度RepeatMasker结果生成初步masked genome
2. 使用最终consensus序列进行第二轮精细masking
目标：低假阳性、低假阴性
"""

import logging
import os
import tempfile
import subprocess
from typing import Dict, List, Set, Tuple, Optional
from pathlib import Path
import numpy as np
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord

from config import PipelineConfig
from utils.robust_runner import RobustRunner

logger = logging.getLogger(__name__)

class GenomeMasker:
    """Phase 4: 高质量基因组Masking"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        self.runner = RobustRunner(config)
        
        # Masking参数
        self.min_rm_score = 225  # RepeatMasker最小分数（高可信度）
        self.min_identity = 80.0  # 最小相似度
        self.min_length = 50  # 最小mask长度
        
        # 第二轮masking参数（为RECON优化：平衡假阳性和假阴性）
        self.round2_min_identity = 75.0  # 略微降低，保留更多潜在重复元素供RECON发现
        self.round2_min_coverage = 0.7   # 适度放宽，避免漏掉部分重复
        self.round2_strict_mode = False  # RECON友好模式：保留边界区域
        
        logger.info(f"Phase 4 initialized: min_score={self.min_rm_score}, "
                   f"min_identity={self.min_identity}%")
    
    def run(self, phase1_output: Dict, phase3_output: Dict) -> Dict[str, any]:
        """执行Phase 4完整流程"""
        logger.info("="*60)
        logger.info("Phase 4: Genome Masking")
        logger.info("="*60)
        
        # 步骤1：收集高质量序列ID
        high_quality_ids = self._collect_high_quality_ids(phase1_output, phase3_output)
        logger.info(f"Collected {len(high_quality_ids)} high-quality sequence IDs")
        
        # 步骤2：过滤Phase 1的RepeatMasker结果
        filtered_rm_results = self._filter_repeatmasker_results(
            phase1_output.get('rm_detailed_results', {}),
            high_quality_ids
        )
        logger.info(f"Filtered RepeatMasker results: {self._count_total_hits(filtered_rm_results)} high-confidence hits")
        
        # 步骤3：生成初步masked genome
        preliminary_masked = self._generate_preliminary_mask(
            self.config.genome_file,
            filtered_rm_results
        )
        logger.info(f"Generated preliminary masked genome: {preliminary_masked}")
        
        # 步骤4：准备最终consensus库
        consensus_library = self._prepare_consensus_library(phase3_output)
        logger.info(f"Prepared consensus library with {len(consensus_library)} sequences")
        
        # 步骤5：第二轮精细masking
        final_masked = self._perform_second_round_masking(
            preliminary_masked,
            consensus_library
        )
        logger.info(f"Generated final masked genome: {final_masked}")
        
        # 步骤6：计算masking统计
        stats = self._calculate_masking_stats(
            self.config.genome_file,
            preliminary_masked,
            final_masked
        )
        
        # 步骤7：生成输出文件
        output_files = self._generate_output_files(
            preliminary_masked,
            final_masked,
            stats
        )
        
        # 计算注释比例并写入文件供RECON使用
        annotation_ratio = stats['final_masked_percent'] / 100.0  # 转换为0-1范围
        annotation_file = Path(self.config.output_dir) / "annotation_ratio.txt"
        
        with open(annotation_file, 'w') as f:
            f.write(f"{annotation_ratio:.6f}\n")
            f.write(f"# Annotation ratio: {stats['final_masked_percent']:.2f}%\n")
            f.write(f"# Masked bases: {stats['final_masked_bp']:,}\n")
            f.write(f"# Total bases: {stats['genome_size']:,}\n")
            f.write(f"# Generated by Phase 4 Genome Masking\n")
        
        logger.info(f"Annotation ratio ({annotation_ratio:.4f}) written to {annotation_file}")
        
        return {
            'preliminary_masked': preliminary_masked,
            'final_masked': final_masked,
            'statistics': stats,
            'annotation_ratio': annotation_ratio,
            'annotation_file': str(annotation_file),
            'output_files': output_files,
            'summary': f"Hard-masked {stats['final_masked_percent']:.2f}% of genome (annotation ratio: {annotation_ratio:.4f})"
        }
    
    def _collect_high_quality_ids(self, phase1_output: Dict, phase3_output: Dict) -> Set[str]:
        """收集高质量序列的ID"""
        high_quality_ids = set()
        
        # 添加所有A类序列
        for seq in phase1_output.get('a_sequences', []):
            high_quality_ids.add(seq['id'])
        
        # 添加高分B类序列（分数>0.65）
        scores = phase1_output.get('scores', {})
        for seq in phase1_output.get('b_sequences', []):
            if scores.get(seq['id'], {}).get('final', 0) > 0.65:
                high_quality_ids.add(seq['id'])
        
        # 添加最终consensus序列的原始ID
        for seq in phase3_output.get('masking_library', []):
            if 'seed_id' in seq:
                high_quality_ids.add(seq['seed_id'])
        
        return high_quality_ids
    
    def _filter_repeatmasker_results(self, rm_results: Dict, high_quality_ids: Set[str]) -> Dict:
        """过滤RepeatMasker结果，只保留高可信度的hits"""
        filtered = {}
        total_hits = 0
        filtered_hits = 0
        
        for seq_id, result in rm_results.items():
            # 只处理高质量序列
            if seq_id not in high_quality_ids:
                continue
            
            filtered_result = {
                'hits': [],
                'total_coverage': 0,
                'hit_count': 0
            }
            
            for hit in result.get('hits', []):
                total_hits += 1
                
                # 过滤条件
                if (hit.get('score', 0) >= self.min_rm_score and
                    hit.get('identity', 0) >= self.min_identity and
                    (hit.get('end', 0) - hit.get('start', 0)) >= self.min_length):
                    
                    filtered_result['hits'].append(hit)
                    filtered_result['hit_count'] += 1
                    filtered_result['total_coverage'] += hit.get('end', 0) - hit.get('start', 0)
                    filtered_hits += 1
            
            if filtered_result['hits']:
                filtered[seq_id] = filtered_result
        
        logger.info(f"Filtered RepeatMasker hits: {filtered_hits}/{total_hits} "
                   f"({filtered_hits/total_hits*100:.1f}%) passed quality threshold")
        
        return filtered
    
    def _count_total_hits(self, rm_results: Dict) -> int:
        """统计总hits数"""
        return sum(len(result.get('hits', [])) for result in rm_results.values())
    
    def _generate_preliminary_mask(self, genome_file: str, filtered_rm_results: Dict) -> str:
        """使用过滤后的RepeatMasker结果生成初步masked genome"""
        output_file = Path(self.config.output_dir) / "genome_preliminary_masked.fa"
        
        # 读取基因组
        genome_dict = {}
        for record in SeqIO.parse(genome_file, "fasta"):
            genome_dict[record.id] = list(str(record.seq))
        
        # 收集所有需要mask的区域
        mask_regions = []
        for seq_id, result in filtered_rm_results.items():
            for hit in result['hits']:
                mask_regions.append({
                    'chrom': hit['chrom'],
                    'start': hit['start'] - 1,  # 转换为0-based
                    'end': hit['end'],
                    'score': hit.get('score', 0),
                    'identity': hit.get('identity', 0)
                })
        
        # 按染色体和位置排序
        mask_regions.sort(key=lambda x: (x['chrom'], x['start']))
        
        # 合并重叠区域
        merged_regions = self._merge_overlapping_regions(mask_regions)
        
        # 应用hard mask (将重复区域替换为N)
        masked_bp = 0
        for region in merged_regions:
            chrom = region['chrom']
            if chrom in genome_dict:
                for i in range(region['start'], min(region['end'], len(genome_dict[chrom]))):
                    if genome_dict[chrom][i] not in 'Nn':
                        genome_dict[chrom][i] = 'N'  # Hard mask: 用N替换
                        masked_bp += 1
        
        # 写出masked genome
        masked_records = []
        for chrom_id, seq_list in genome_dict.items():
            masked_seq = ''.join(seq_list)
            record = SeqRecord(
                Seq(masked_seq),
                id=chrom_id,
                description=f"preliminary masked"
            )
            masked_records.append(record)
        
        with open(output_file, 'w') as f:
            SeqIO.write(masked_records, f, "fasta")
        
        total_bp = sum(len(seq) for seq in genome_dict.values())
        logger.info(f"Preliminary masking: {masked_bp:,} bp ({masked_bp/total_bp*100:.2f}%)")
        
        return str(output_file)
    
    def _merge_overlapping_regions(self, regions: List[Dict]) -> List[Dict]:
        """合并重叠的mask区域"""
        if not regions:
            return []
        
        merged = []
        current = regions[0].copy()
        
        for region in regions[1:]:
            if region['chrom'] == current['chrom'] and region['start'] <= current['end']:
                # 重叠，合并
                current['end'] = max(current['end'], region['end'])
                current['score'] = max(current['score'], region['score'])
                current['identity'] = max(current['identity'], region['identity'])
            else:
                # 不重叠，保存当前并开始新的
                merged.append(current)
                current = region.copy()
        
        merged.append(current)
        return merged
    
    def _prepare_consensus_library(self, phase3_output: Dict) -> List[Dict]:
        """准备用于第二轮masking的consensus库"""
        consensus_library = []
        
        # 使用masking库（95%去冗余）
        for seq_data in phase3_output.get('masking_library', []):
            consensus_library.append({
                'id': seq_data['id'],
                'sequence': seq_data['sequence'],
                'num_copies': seq_data.get('num_copies', 1)
            })
        
        return consensus_library
    
    def _perform_second_round_masking(self, preliminary_masked: str, 
                                     consensus_library: List[Dict]) -> str:
        """使用最终consensus序列进行第二轮精细masking"""
        output_file = Path(self.config.output_dir) / "genome_final_masked.fa"
        
        # 创建临时consensus库文件
        with tempfile.NamedTemporaryFile(mode='w', suffix='.fa', delete=False) as lib_file:
            for seq_data in consensus_library:
                lib_file.write(f">{seq_data['id']}\n{seq_data['sequence']}\n")
            lib_file_path = lib_file.name
        
        # 运行RepeatMasker进行第二轮masking
        try:
            # 构建RepeatMasker命令（为RECON优化的参数）
            cmd = [
                self.config.repeatmasker_exe,
                '-lib', lib_file_path,
                '-no_is',  # 不搜索细菌插入序列
                '-nolow',  # 不mask低复杂度区域，让RECON处理
                '-div', str(100 - self.round2_min_identity),  # 允许25%分歧，保留古老TEs
                '-cutoff', '200',  # 降低cutoff，保留更多候选
                '-s',      # 慢速但更敏感的搜索
                '-small',  # 返回较短的匹配，保留RECON发现机会
                '-pa', str(self.config.threads),
                '-dir', str(Path(self.config.output_dir) / 'round2_rm'),
                preliminary_masked
            ]
            
            # 如果启用RECON友好模式，添加额外参数
            if self.round2_strict_mode == False:
                cmd.extend([
                    '-frag', '20'  # 允许片段化匹配
                    # Note: removed invalid -maxsize option that doesn't exist in RepeatMasker
                ])
            
            logger.info("Using RECON-optimized parameters for second round masking:")
            logger.info(f"  - Identity threshold: {self.round2_min_identity}%")
            logger.info(f"  - Sensitive mode: enabled")
            logger.info(f"  - Fragment matching: enabled")
            
            logger.info(f"Running second round RepeatMasker with {len(consensus_library)} consensus sequences")
            
            # 创建输出目录
            os.makedirs(Path(self.config.output_dir) / 'round2_rm', exist_ok=True)
            
            # 运行RepeatMasker
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=7200)  # 2小时超时
            
            if result.returncode != 0:
                logger.warning(f"Second round RepeatMasker failed: {result.stderr}")
                # 如果失败，返回初步masked结果
                return preliminary_masked
            
            # 找到masked输出文件
            masked_file = Path(self.config.output_dir) / 'round2_rm' / f"{Path(preliminary_masked).name}.masked"
            
            if masked_file.exists():
                # 移动到最终位置
                import shutil
                shutil.move(str(masked_file), str(output_file))
                logger.info(f"Second round masking completed: {output_file}")
                return str(output_file)
            else:
                logger.warning("Second round masked file not found, using preliminary result")
                return preliminary_masked
                
        except Exception as e:
            logger.error(f"Second round masking failed: {e}")
            return preliminary_masked
        finally:
            # 清理临时文件
            if os.path.exists(lib_file_path):
                os.unlink(lib_file_path)
    
    def _calculate_masking_stats(self, original_genome: str, 
                                preliminary_masked: str, 
                                final_masked: str) -> Dict:
        """计算masking统计信息"""
        stats = {
            'genome_size': 0,
            'preliminary_masked_bp': 0,
            'final_masked_bp': 0,
            'preliminary_masked_percent': 0,
            'final_masked_percent': 0,
            'additional_masked_bp': 0,
            'chromosomes': {}
        }
        
        # 分析原始基因组
        for record in SeqIO.parse(original_genome, "fasta"):
            seq_str = str(record.seq)
            stats['genome_size'] += len(seq_str)
        
        # 分析初步masked (现在是hard mask，只计算N)
        if os.path.exists(preliminary_masked):
            for record in SeqIO.parse(preliminary_masked, "fasta"):
                seq_str = str(record.seq)
                masked_count = sum(1 for c in seq_str if c in 'Nn')  # 只计算N
                stats['preliminary_masked_bp'] += masked_count
                stats['chromosomes'][record.id] = {
                    'size': len(seq_str),
                    'preliminary_masked': masked_count
                }
        
        # 分析最终masked (现在是hard mask，只计算N)
        if os.path.exists(final_masked):
            for record in SeqIO.parse(final_masked, "fasta"):
                seq_str = str(record.seq)
                masked_count = sum(1 for c in seq_str if c in 'Nn')  # 只计算N
                stats['final_masked_bp'] += masked_count
                if record.id in stats['chromosomes']:
                    stats['chromosomes'][record.id]['final_masked'] = masked_count
        
        # 计算百分比
        if stats['genome_size'] > 0:
            stats['preliminary_masked_percent'] = stats['preliminary_masked_bp'] / stats['genome_size'] * 100
            stats['final_masked_percent'] = stats['final_masked_bp'] / stats['genome_size'] * 100
            stats['additional_masked_bp'] = stats['final_masked_bp'] - stats['preliminary_masked_bp']
        
        return stats
    
    def _generate_output_files(self, preliminary_masked: str, 
                              final_masked: str, 
                              stats: Dict) -> Dict:
        """生成输出文件和报告"""
        output_files = {
            'preliminary_masked': preliminary_masked,
            'final_masked': final_masked,
            'stats_file': str(Path(self.config.output_dir) / 'masking_statistics.txt'),
            'summary_file': str(Path(self.config.output_dir) / 'masking_summary.txt')
        }
        
        # 写统计文件
        with open(output_files['stats_file'], 'w') as f:
            f.write("Genome Masking Statistics\n")
            f.write("="*60 + "\n\n")
            f.write(f"Genome size: {stats['genome_size']:,} bp\n")
            f.write(f"Preliminary masked: {stats['preliminary_masked_bp']:,} bp ({stats['preliminary_masked_percent']:.2f}%)\n")
            f.write(f"Final masked: {stats['final_masked_bp']:,} bp ({stats['final_masked_percent']:.2f}%)\n")
            f.write(f"Additional masked: {stats['additional_masked_bp']:,} bp\n")
            f.write("\nPer-chromosome statistics:\n")
            f.write("-"*60 + "\n")
            
            for chrom_id, chrom_stats in stats['chromosomes'].items():
                f.write(f"{chrom_id}:\n")
                f.write(f"  Size: {chrom_stats['size']:,} bp\n")
                f.write(f"  Preliminary: {chrom_stats.get('preliminary_masked', 0):,} bp\n")
                f.write(f"  Final: {chrom_stats.get('final_masked', 0):,} bp\n")
        
        # 写摘要文件
        with open(output_files['summary_file'], 'w') as f:
            f.write("Phase 4: Genome Masking Summary\n")
            f.write("="*60 + "\n\n")
            f.write("Two-step masking strategy:\n")
            f.write("1. High-confidence RepeatMasker hits from Phase 1\n")
            f.write("2. Final consensus sequences from Phase 3\n\n")
            f.write(f"Results:\n")
            f.write(f"- Total genome masked: {stats['final_masked_percent']:.2f}%\n")
            f.write(f"- Low false positive rate achieved through strict thresholds\n")
            f.write(f"- Low false negative rate through two-round masking\n")
        
        logger.info(f"Output files written to {self.config.output_dir}")
        
        return output_files