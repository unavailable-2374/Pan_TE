#!/usr/bin/env python3
import logging
import argparse
import json
import pickle
from pathlib import Path
from typing import Dict, Any

from config import PipelineConfig
from phase1_screening_optimized import SequenceScreenerOptimized
from phase2_chimera_splitting import ChimeraSplitter
from phase3_consensus_building import ConsensusBuilder
from phase4_genome_masking import GenomeMasker
from utils.robust_runner import RobustRunner
from legacy_adapter import LegacyPhase1Adapter, convert_legacy_phase1

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TEConsensusPipelineWithLegacy:
    """
    æ”¯æŒåŠ è½½æ—§Phase1ç»“æœçš„TEå…±è¯†åºåˆ—æ„å»ºæµæ°´çº¿
    
    ç”¨æ³•:
    1. ä»å¤´å¼€å§‹è¿è¡Œ: python main_with_legacy.py -r repeatscout.fa -g genome.fa -o output
    2. ä»æ—§Phase1ç»“æœç»§ç»­: python main_with_legacy.py --load-phase1 old_phase1.pkl -g genome.fa -o output
    """
    
    def __init__(self, config: PipelineConfig, phase1_result_path: str = None):
        self.config = config
        self.runner = RobustRunner(config)
        self.phase1_result_path = phase1_result_path
        
        logger.info("Initializing TE Consensus Pipeline with Legacy Support:")
        logger.info("  Phase 1: Candidate identification (can load legacy results)")
        logger.info("  Phase 2: Chimera detection & splitting")
        logger.info("  Phase 3: Comprehensive consensus building")
        logger.info("  Phase 4: Genome masking preparation")
        
        # åªæœ‰åœ¨ä¸åŠ è½½æ—§ç»“æœæ—¶æ‰åˆå§‹åŒ–Phase1
        if not phase1_result_path:
            self.phase1 = SequenceScreenerOptimized(config)
        else:
            self.phase1 = None
            logger.info(f"Will load Phase1 results from: {phase1_result_path}")
        
        self.phase2 = ChimeraSplitter(config)
        self.phase3 = ConsensusBuilder(config)
        self.phase4 = GenomeMasker(config)
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        for dir_path in [config.output_dir, config.temp_dir, 
                        config.cache_dir, config.checkpoint_dir]:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def run(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´æµç¨‹"""
        logger.info("="*60)
        logger.info("Starting TE Consensus Pipeline with Legacy Support")
        if self.phase1_result_path:
            logger.info(f"Loading Phase1 results from: {self.phase1_result_path}")
        else:
            logger.info(f"Input: {self.config.repeatscout_file}")
        logger.info(f"Genome: {self.config.genome_file}")
        logger.info(f"Output: {self.config.output_dir}")
        logger.info("="*60)
        
        try:
            # Phase 1: è·å–å€™é€‰åºåˆ—ï¼ˆåŠ è½½æ—§ç»“æœæˆ–é‡æ–°è¿è¡Œï¼‰
            if self.phase1_result_path:
                logger.info("\n>>> Phase 1: Loading Legacy Results")
                phase1_output = self._load_and_convert_phase1_results()
            else:
                logger.info("\n>>> Phase 1: Consensus Candidate Identification")
                phase1_output = self.runner.run_with_checkpoint(
                    self.phase1.run,
                    checkpoint_name="phase1_complete"
                )
            
            logger.info(f"Phase 1 complete: {phase1_output['summary']}")
            
            # Phase 2: åµŒåˆä½“æ£€æµ‹å’Œæ‹†åˆ†
            logger.info("\n>>> Phase 2: Chimera Detection and Splitting")
            phase2_output = self.runner.run_with_checkpoint(
                lambda: self.phase2.run(phase1_output),
                checkpoint_name="phase2_complete"
            )
            # Phase2ç»Ÿè®¡ä¿¡æ¯
            phase2_stats = phase2_output.get('statistics', {})
            logger.info(f"Phase 2 complete: Processed {phase2_stats.get('input_candidates', 0)} candidate sequences")
            logger.info(f"  - Chimeric sequences detected: {phase2_stats.get('chimeric_sequences', 0)}")
            logger.info(f"  - Successfully split: {phase2_stats.get('split_sequences', 0)}")
            logger.info(f"  - Output sequences for Phase 3: {phase2_stats.get('output_total', 0)}")
            
            # Phase 3: å…¨é¢å…±è¯†æ„å»º
            logger.info("\n>>> Phase 3: Comprehensive Consensus Building")
            phase3_output = self.runner.run_with_checkpoint(
                lambda: self.phase3.run(phase2_output),
                checkpoint_name="phase3_complete"
            )
            # Phase3ç»Ÿè®¡ä¿¡æ¯
            phase3_stats = phase3_output.get('statistics', {})
            logger.info(f"Phase 3 complete: Generated {phase3_stats.get('total_consensus', 0)} consensus sequences")
            logger.info(f"  - High quality: {phase3_stats.get('high_quality_consensus', 0)}")
            logger.info(f"  - Medium quality: {phase3_stats.get('medium_quality_consensus', 0)}")
            logger.info(f"  - Low quality: {phase3_stats.get('low_quality_consensus', 0)}")
            if 'deduplicated_sequences' in phase3_stats:
                logger.info(f"  - Removed duplicates: {phase3_stats['deduplicated_sequences']}")
            
            # Phase 4: åŸºå› ç»„å±è”½
            logger.info("\n>>> Phase 4: Genome Masking")
            phase4_output = self.runner.run_with_checkpoint(
                lambda: self.phase4.run(phase3_output),
                checkpoint_name="phase4_complete"
            )
            # Phase4ç»Ÿè®¡ä¿¡æ¯
            phase4_stats = phase4_output.get('statistics', {})
            logger.info(f"Phase 4 complete: Masked genome ready")
            if 'masking_coverage' in phase4_stats:
                logger.info(f"  - Masking coverage: {phase4_stats['masking_coverage']:.2%}")
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_results = self._compile_final_results(
                phase1_output, phase2_output, phase3_output, phase4_output
            )
            
            logger.info("\n" + "="*60)
            logger.info("TE Consensus Pipeline Completed Successfully!")
            logger.info(f"Final consensus library: {len(phase3_output['consensus_sequences'])} sequences")
            logger.info(f"Masked genome ready for RECON")
            logger.info("="*60)
            
            return final_results
            
        except Exception as e:
            logger.error(f"Pipeline failed: {e}")
            raise
    
    def _load_and_convert_phase1_results(self) -> Dict[str, Any]:
        """åŠ è½½å¹¶è½¬æ¢æ—§çš„Phase1ç»“æœ"""
        try:
            logger.info(f"Loading legacy Phase1 results from {self.phase1_result_path}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢
            phase1_path = Path(self.phase1_result_path)
            converted_path = phase1_path.parent / f"{phase1_path.stem}_converted{phase1_path.suffix}"
            
            if converted_path.exists():
                logger.info(f"Found converted file: {converted_path}")
                # ç›´æ¥åŠ è½½è½¬æ¢åçš„ç»“æœ
                if converted_path.suffix == '.pkl':
                    with open(converted_path, 'rb') as f:
                        converted_data = pickle.load(f)
                elif converted_path.suffix == '.json':
                    with open(converted_path, 'r') as f:
                        converted_data = json.load(f)
                else:
                    raise ValueError(f"Unsupported file format: {converted_path}")
            else:
                logger.info("Converting legacy format to new pipeline format...")
                # ä½¿ç”¨é€‚é…å™¨è½¬æ¢
                adapter = LegacyPhase1Adapter(self.phase1_result_path)
                if not adapter.load_old_results():
                    raise RuntimeError("Failed to load legacy Phase1 results")
                
                converted_data = adapter.convert_to_new_format()
                
                # ä¿å­˜è½¬æ¢åçš„ç»“æœä»¥å¤‡ä¸‹æ¬¡ä½¿ç”¨
                adapter.save_converted_results(str(converted_path), converted_data)
                logger.info(f"Saved converted results for future use: {converted_path}")
            
            # éªŒè¯è½¬æ¢åçš„æ•°æ®
            self._validate_phase1_data(converted_data)
            
            logger.info("Legacy Phase1 results loaded and converted successfully")
            return converted_data
            
        except Exception as e:
            logger.error(f"Failed to load/convert Phase1 results: {e}")
            raise
    
    def _validate_phase1_data(self, data: Dict[str, Any]):
        """éªŒè¯Phase1æ•°æ®æ ¼å¼"""
        required_keys = ['consensus_candidates', 'scores', 'rm_detailed_results']
        for key in required_keys:
            if key not in data:
                raise ValueError(f"Missing required key in Phase1 data: {key}")
        
        candidates = data['consensus_candidates']
        if not isinstance(candidates, list):
            raise ValueError("consensus_candidates must be a list")
        
        # æ£€æŸ¥å€™é€‰åºåˆ—æ ¼å¼
        for candidate in candidates[:5]:  # æ£€æŸ¥å‰5ä¸ª
            if 'id' not in candidate or 'sequence' not in candidate:
                raise ValueError("Each candidate must have 'id' and 'sequence' fields")
        
        logger.info(f"Phase1 data validation passed: {len(candidates)} candidates")
    
    def _compile_final_results(self, phase1_output, phase2_output, phase3_output, phase4_output) -> Dict[str, Any]:
        """ç¼–è¯‘æœ€ç»ˆç»“æœ"""
        return {
            'phase1_summary': phase1_output.get('summary', ''),
            'phase2_statistics': phase2_output.get('statistics', {}),
            'phase3_statistics': phase3_output.get('statistics', {}),
            'phase4_statistics': phase4_output.get('statistics', {}),
            'final_consensus_sequences': phase3_output.get('consensus_sequences', []),
            'masked_genome_path': phase4_output.get('masked_genome_path', ''),
            'pipeline_complete': True
        }


def main():
    parser = argparse.ArgumentParser(description='TE Consensus Building Pipeline with Legacy Support')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('-r', '--repeatscout', help='RepeatScout output file')
    parser.add_argument('-g', '--genome', required=True, help='Genome file (FASTA)')
    parser.add_argument('-o', '--output', required=True, help='Output directory')
    
    # Legacyæ”¯æŒ
    parser.add_argument('--load-phase1', help='Load legacy Phase1 results (.pkl or .json)')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('-t', '--threads', type=int, default=8, help='Number of threads (default: 8)')
    parser.add_argument('-c', '--config', help='Configuration file (JSON)')
    parser.add_argument('--resume', action='store_true', help='Resume from checkpoints')
    parser.add_argument('--clear-cache', action='store_true', help='Clear cache before running')
    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # éªŒè¯å‚æ•°
    if not args.load_phase1 and not args.repeatscout:
        parser.error("Either --repeatscout or --load-phase1 must be specified")
    
    if args.load_phase1 and not Path(args.load_phase1).exists():
        parser.error(f"Phase1 result file not found: {args.load_phase1}")
    
    try:
        # åˆ›å»ºé…ç½®
        if args.config and Path(args.config).exists():
            config = PipelineConfig.load(args.config)
            # æ›´æ–°å‘½ä»¤è¡Œå‚æ•°
            config.genome_file = args.genome
            config.output_dir = args.output
            config.threads = args.threads
            if args.repeatscout:
                config.repeatscout_file = args.repeatscout
        else:
            # å¦‚æœåŠ è½½æ—§ç»“æœï¼Œrepeatscoutæ–‡ä»¶å¯ä»¥ä¸ºNone
            repeatscout_file = args.repeatscout if args.repeatscout else "dummy.fa"
            config = PipelineConfig(
                repeatscout_file=repeatscout_file,
                genome_file=args.genome,
                output_dir=args.output,
                threads=args.threads
            )
        
        # è®¾ç½®é€‰é¡¹
        if args.clear_cache and hasattr(config, 'clear_cache'):
            config.clear_cache = True
        
        # åˆ›å»ºå¹¶è¿è¡Œæµæ°´çº¿
        pipeline = TEConsensusPipelineWithLegacy(
            config=config,
            phase1_result_path=args.load_phase1
        )
        
        results = pipeline.run()
        
        print("\nâœ… Pipeline completed successfully!")
        print(f"ğŸ“Š Final consensus sequences: {len(results['final_consensus_sequences'])}")
        if results.get('masked_genome_path'):
            print(f"ğŸ§¬ Masked genome: {results['masked_genome_path']}")
        
    except Exception as e:
        print(f"âŒ Pipeline failed: {e}")
        logger.exception("Detailed error information:")
        exit(1)


if __name__ == "__main__":
    main()