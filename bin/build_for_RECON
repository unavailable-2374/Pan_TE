#!/usr/bin/env perl
use strict;
use warnings;
use FindBin;
use File::Basename;
use Parallel::ForkManager;

# Simple version of build_for_RECON that avoids RepeatModeler dependencies
# Focus on core functionality

our %families = ();
# Enhanced thresholds for higher quality consensus
our $familySizeCutoff = 15;          # Process families with 15 or more elements  
our $minConsensusLength = 50;        # Minimum consensus sequence length (reduced from 100)
our $minRefinerScore = 150;          # Restored original score threshold
our $minAlignmentSize = 8;           # Reduced minimum alignment size (from 8 to 5)
our $maxLowComplexity = 0.55;         # Slightly more permissive for low complexity
our $DEBUG = 0;  # Disable debug for production

die "Usage: $0 workDir genomeDB total_threads\n" unless @ARGV == 3;
my ($workDir, $genomeDB, $threads) = @ARGV;

# Production version - minimal output

# Check if consensus building is already completed
if (-f "$workDir/consensus.ok" && -s "$workDir/consensi.fa") {
    print "Consensus building already completed (consensus.ok exists)\n";
    my $count = `grep -c '^>' $workDir/consensi.fa 2>/dev/null || echo 0`;
    chomp $count;
    print "Found $count existing consensus sequences in consensi.fa\n";
    exit 0;
}

# Load sequences into memory for faster access
my %sequences = load_fasta_sequences($genomeDB);
print "Loaded " . scalar(keys %sequences) . " sequences from genome database\n";

# Process RECON output
%families = process_recon_output($workDir);
my $family_count = scalar(keys(%families));
print "Number of families returned by RECON: $family_count\n";
print "Processing families with greater than $familySizeCutoff elements\n";

# Process families and create family files
my %refinableFamilies = process_families(\%families, \%sequences, $workDir);
print "Created " . scalar(keys %refinableFamilies) . " refinable families\n";

# Run Refiner on each family
run_parallel_refiners(\%refinableFamilies, $workDir, $threads);

# Combine refined results
process_refined_families(\%families, \%refinableFamilies, $workDir);

# Create consensus.ok checkpoint after successful completion
if (-s "$workDir/consensi.fa") {
    open my $fh_ok, '>', "$workDir/consensus.ok" or die "Cannot create consensus.ok: $!";
    print $fh_ok "Consensus building completed at " . localtime() . "\n";
    my $count = `grep -c '^>' $workDir/consensi.fa 2>/dev/null || echo 0`;
    chomp $count;
    print $fh_ok "Consensus sequences: $count\n";
    print $fh_ok "File size: " . (-s "$workDir/consensi.fa") . " bytes\n";
    close $fh_ok;
    print "Created consensus.ok checkpoint\n";
}

# Clean up temporary files after successful completion
cleanup_refiner_files($workDir);

print "=== Processing completed ===\n";

sub load_fasta_sequences {
    my $fasta_file = shift;
    my %seqs;
    
    print "Loading sequences from $fasta_file...\n";
    
    open my $fh, '<', $fasta_file or die "Cannot open $fasta_file: $!";
    
    my $current_id;
    my $current_seq = '';
    
    while (<$fh>) {
        chomp;
        if (/^>(.+)/) {
            # Save previous sequence
            if ($current_id) {
                $seqs{$current_id} = $current_seq;
            }
            # Start new sequence - extract just the ID part (before first space)
            my $full_header = $1;
            # Extract the first part (e.g., "gi|1" from "gi|1 unmasked_region_1 from_chr25:2883748-3383748")
            my ($seq_id) = split /\s+/, $full_header, 2;
            $current_id = $seq_id;
            $current_seq = '';
        } else {
            $current_seq .= $_;
        }
    }
    
    # Save last sequence
    if ($current_id) {
        $seqs{$current_id} = $current_seq;
    }
    
    close $fh;
    return %seqs;
}

sub process_recon_output {
    my $workDir = shift;
    my %families;
    
    my $eles_file = "$workDir/summary/eles";
    die "Error: Recon failed to produce the summary/eles file!\n" unless -f $eles_file;
    
    print "Processing $eles_file...\n";
    
    open my $fh, '<', $eles_file or die "Cannot open eles file: $!";
    my $line_count = 0;
    
    while (<$fh>) {
        chomp;
        $line_count++;
        
        # Skip header and empty lines
        next if /^#/ || /^\s*$/;
        
        # Parse: fam ele dir sequence start end (note: first field is empty due to leading spaces)
        my @fields = split /\s+/;
        next unless @fields >= 7;  # Need 7 fields because first is empty
        
        # Skip the leading empty field due to formatting
        my ($empty, $fam_id, $ele_id, $orient, $seq_name, $start, $end) = @fields;
        
        # Skip invalid coordinates
        next if $start < 0 || $end < 0 || $end <= $start;
        
        # Debug first few entries
        if ($line_count <= 10 && $DEBUG) {
            print "DEBUG: Line $line_count: fam=$fam_id, ele=$ele_id, seq=$seq_name, start=$start, end=$end\n";
        }
        
        # Store family element
        $families{$fam_id}->{elements} ||= [];
        push @{$families{$fam_id}->{elements}}, {
            seqName   => $seq_name,
            elementID => $ele_id,
            orient    => $orient,
            start     => $start,
            end       => $end
        };
    }
    close $fh;
    
    print "Processed $line_count lines from eles file\n";
    return %families;
}

sub process_families {
    my ($families_ref, $sequences_ref, $workDir) = @_;
    my %refinableFamilies;
    
    # Open consensus output file - use temporary file to avoid data loss
    my $temp_consensi = "$workDir/consensi.fa.tmp";
    open my $fh_cons, '>', $temp_consensi or die "Cannot create $temp_consensi: $!";
    
    # Process families sorted by size
    my @sortedKeys = sort {
        @{$families_ref->{$b}->{elements}} <=> @{$families_ref->{$a}->{elements}}
    } keys %$families_ref;
    
    my $processed_count = 0;
    my $max_families_to_process = $DEBUG ? 5 : 999999;  # Limit for debugging
    
    foreach my $familyID (@sortedKeys) {
        my $element_count = @{$families_ref->{$familyID}->{elements}};
        
        # Skip small families with enhanced threshold
        last if $element_count < $familySizeCutoff;
        
        # Stop after processing max families in debug mode
        last if $processed_count >= $max_families_to_process;
        
        $processed_count++;
        if ($DEBUG && $processed_count <= 5) {
            print "Processing family $familyID with $element_count elements\n";
        }
        
        # Create family file
        my $success = process_single_family($familyID, $families_ref, $sequences_ref, $workDir);
        
        if ($success) {
            $refinableFamilies{$familyID}++;
        }
    }
    
    close $fh_cons;
    
    # Move temp file to final location only if we have data
    if (-s $temp_consensi) {
        rename($temp_consensi, "$workDir/consensi.fa") or die "Cannot rename temp file: $!";
    } else {
        unlink $temp_consensi;  # Remove empty temp file
    }
    
    print "Processed $processed_count families for refinement\n";
    return %refinableFamilies;
}

sub process_single_family {
    my ($familyID, $families_ref, $sequences_ref, $workDir) = @_;
    
    my $family_file = "$workDir/family-$familyID.fa";
    my $refiner_output = "$family_file.refiner_cons";
    
    # Skip if already processed (check for refiner output)
    if (-s $refiner_output) {
        print "Family $familyID already processed (refiner output exists)\n" if $DEBUG;
        return 1;  # Consider it successful
    }
    
    open my $fh_fam, '>', $family_file or die "Cannot create $family_file: $!";
    
    my $elementsRef = $families_ref->{$familyID}->{elements};
    my $giID = 1;
    my $written_count = 0;
    
    # Sort elements by size (largest first)
    my @sorted_elements = sort {
        ($b->{end} - $b->{start}) <=> ($a->{end} - $a->{start})
    } @$elementsRef;
    
    foreach my $elementRef (@sorted_elements) {
        my $seqName = $elementRef->{seqName};
        my $startOffset = $elementRef->{start};  # 1-based
        my $endOffset = $elementRef->{end};      # 1-based
        
        # Find sequence in our hash
        if (!exists $sequences_ref->{$seqName}) {
            if ($DEBUG && $written_count < 3) {
                print "WARNING: Sequence $seqName not found in database\n";
            }
            next;
        }
        
        my $full_sequence = $sequences_ref->{$seqName};
        my $seq_length = length($full_sequence);
        
        # Check bounds
        if ($endOffset > $seq_length || $startOffset < 1) {
            if ($DEBUG && $written_count < 3) {
                print "WARNING: Coordinates out of bounds for $seqName: $startOffset-$endOffset (length: $seq_length)\n";
            }
            next;
        }
        
        # Extract subsequence (convert to 0-based for substr)
        my $extract_length = $endOffset - $startOffset + 1;
        my $sequence = substr($full_sequence, $startOffset - 1, $extract_length);
        
        # Handle reverse orientation
        if ($elementRef->{orient} ne "1") {
            $sequence = reverse($sequence);
            $sequence =~ tr/ACGTYRMKHBVD/TGCARYKMDVBH/;
        }
        
        # Write to family file
        print $fh_fam ">gi|$giID $seqName:$startOffset-$endOffset element-$elementRef->{elementID}\n";
        print $fh_fam "$sequence\n";
        $giID++;
        $written_count++;
        
        # Debug first few sequences
        if ($DEBUG && $written_count <= 2) {
            print "DEBUG: Wrote sequence $written_count for family $familyID: $seqName:$startOffset-$endOffset (length: " . length($sequence) . ")\n";
        }
    }
    
    close $fh_fam;
    
    if ($written_count > 0) {
        print "Created family-$familyID.fa with $written_count sequences\n" if $DEBUG;
        return 1;
    } else {
        print "WARNING: No sequences written for family $familyID\n";
        unlink $family_file;  # Remove empty file
        return 0;
    }
}

sub run_parallel_refiners {
    my ($refinableFamilies_ref, $workDir, $threads) = @_;
    
    # More flexible thread allocation for better parallelization
    my $max_parallel;
    if ($threads <= 4) {
        $max_parallel = 1;  # Single process for small thread counts
    } elsif ($threads <= 8) {
        $max_parallel = 2;  # 2 processes, ~2-4 threads each
    } elsif ($threads <= 16) {
        $max_parallel = 4;  # 4 processes, ~2-4 threads each
    } else {
        $max_parallel = int($threads / 4);  # 4 threads per process for large counts
    }
    
    print "Running Refiner on " . scalar(keys %$refinableFamilies_ref) . " families with max $max_parallel parallel jobs\n";
    
    my $pm = Parallel::ForkManager->new($max_parallel);
    
    my $processed = 0;
    foreach my $familyID (keys %$refinableFamilies_ref) {
        $pm->start and next;
        
        $processed++;
        my $instancesFile = "family-$familyID.fa";
        my $output_file = "$instancesFile.refiner_cons";
        
        # Run Refiner with enhanced parameters for higher quality
        my $cmd = "$FindBin::RealBin/Refiner.py $instancesFile $output_file -t 4 --min-score $minRefinerScore --gap-init 25 --gap-ext 8 2> refine_$familyID.log";
        
        if ($DEBUG && $processed <= 3) {
            print "Running: $cmd\n";
        }
        
        my $result = system($cmd);
        
        if ($result != 0 && $DEBUG) {
            print "WARNING: Refiner failed for family $familyID (exit code: $result)\n";
        }
        
        $pm->finish;
    }
    
    $pm->wait_all_children;
    print "Completed Refiner processing\n";
}

sub process_refined_families {
    my ($families_ref, $refinableFamilies_ref, $workDir) = @_;
    
    # Check if consensi.fa exists, if not something went wrong
    unless (-f "$workDir/consensi.fa") {
        open my $fh_init, '>', "$workDir/consensi.fa" or die "Cannot create consensi.fa: $!";
        close $fh_init;
    }
    
    open my $fh_cons, '>>', "$workDir/consensi.fa" or die "Cannot append to consensi.fa: $!";
    
    my $consensus_count = 0;
    my $filtered_stats = {
        total_processed => 0,
        filtered_length => 0,
        filtered_alignment => 0, 
        filtered_complexity => 0,
        passed_filters => 0
    };
    
    foreach my $familyID (keys %$refinableFamilies_ref) {
        my $refiner_cons = "$workDir/family-$familyID.fa.refiner_cons";
        
        next unless -s $refiner_cons;  # Skip empty files
        
        open my $fh_in, '<', $refiner_cons or next;
        my ($cons, $maSize) = ('', 1);
        my $in_sequence = 0;
        
        while (<$fh_in>) {
            if (/^>.*consensus from (\d+) copies, method=(\w+)/) {
                $maSize = $1;
                my $method = $2;
                $in_sequence = 1;
                # Enhanced Refiner provides method information
                if ($DEBUG && $consensus_count < 3) {
                    print "Family $familyID: consensus built using method '$method' from $maSize copies\n";
                }
                next;
            } elsif (/^>.*consensus from (\d+) copies/) {
                $maSize = $1;
                $in_sequence = 1;
                next;
            } elsif (/^>/) {
                $in_sequence = 1;
                next;
            } elsif ($in_sequence && !/^>/) {
                chomp;
                $cons .= $_;
            }
        }
        close $fh_in;
        
        next unless $cons;  # Skip if no consensus sequence
        
        $filtered_stats->{total_processed}++;
        
        # Apply quality filters with statistics
        if (length($cons) < $minConsensusLength) {
            $filtered_stats->{filtered_length}++;
            next;
        }
        
        if ($maSize < $minAlignmentSize) {
            $filtered_stats->{filtered_alignment}++;
            next;
        }
        
        # Check for low complexity sequences
        my $low_complexity_ratio = calculate_low_complexity($cons);
        if ($low_complexity_ratio > $maxLowComplexity) {
            $filtered_stats->{filtered_complexity}++;
            next;
        }
        
        $filtered_stats->{passed_filters}++;
        
        # Store in families hash
        $families_ref->{$familyID}->{consensus} = $cons;
        $families_ref->{$familyID}->{finalElementCount} = $maSize;
        
        # Write to consensus file
        my $original_count = @{$families_ref->{$familyID}->{elements}};
        print $fh_cons ">family-$familyID (Recon Family Size = $original_count, Final Multiple Alignment Size = $maSize)\n";
        print $fh_cons "$cons\n";
        
        $consensus_count++;
        
        if ($DEBUG && $consensus_count <= 3) {
            print "Added consensus for family $familyID: " . length($cons) . " bp from $maSize copies\n";
        }
    }
    
    close $fh_cons;
    print "Generated $consensus_count consensus sequences in consensi.fa\n";
    
    # Print filtering statistics
    print "=== Quality Filtering Results ===\n";
    print "Total families processed: $filtered_stats->{total_processed}\n";
    print "Filtered by length (<${minConsensusLength}bp): $filtered_stats->{filtered_length}\n";
    print "Filtered by alignment size (<${minAlignmentSize}): $filtered_stats->{filtered_alignment}\n";
    print "Filtered by low complexity (>${maxLowComplexity}): $filtered_stats->{filtered_complexity}\n";
    print "Passed all filters: $filtered_stats->{passed_filters}\n";
    my $filter_rate = $filtered_stats->{total_processed} > 0 ? 
                     (1 - $filtered_stats->{passed_filters} / $filtered_stats->{total_processed}) * 100 : 0;
    printf "Overall filtering rate: %.1f%%\n", $filter_rate;
}

sub calculate_low_complexity {
    my $sequence = shift;
    my $seq_length = length($sequence);
    return 1.0 if $seq_length == 0;
    
    # Count mono-nucleotide runs and simple repeats
    my $low_complexity_bases = 0;
    
    # Count mono-nucleotide runs (3+ consecutive identical bases)
    while ($sequence =~ /([ATGCN])\1{2,}/gi) {
        $low_complexity_bases += length($&);
    }
    
    # Count simple dinucleotide repeats (6+ bases of pattern)
    while ($sequence =~ /([ATGCN]{2})\1{2,}/gi) {
        $low_complexity_bases += length($&);
    }
    
    # Count simple trinucleotide repeats (9+ bases of pattern)
    while ($sequence =~ /([ATGCN]{3})\1{2,}/gi) {
        $low_complexity_bases += length($&);
    }
    
    return $low_complexity_bases / $seq_length;
}

sub cleanup_refiner_files {
    my ($workDir) = @_;
    
    print "Cleaning up temporary refiner files...\n";
    
    # Count files before cleanup for reporting
    my @family_files = glob("$workDir/family-*.fa");
    my @log_files = glob("$workDir/refine_*.log");
    my @refiner_cons_files = glob("$workDir/family-*.fa.refiner_cons");
    
    my $family_count = scalar(@family_files);
    my $log_count = scalar(@log_files);
    my $cons_count = scalar(@refiner_cons_files);
    
    # Remove family*.fa files
    if (@family_files) {
        foreach my $file (@family_files) {
            if (-f $file) {
                unlink($file) or warn "Could not remove $file: $!";
            }
        }
        print "Removed $family_count family-*.fa files\n";
    }
    
    # Remove refiner log files (refine_*.log)
    if (@log_files) {
        foreach my $file (@log_files) {
            if (-f $file) {
                unlink($file) or warn "Could not remove $file: $!";
            }
        }
        print "Removed $log_count refine_*.log files\n";
    }
    
    # Remove refiner consensus intermediate files (family-*.fa.refiner_cons)
    if (@refiner_cons_files) {
        foreach my $file (@refiner_cons_files) {
            if (-f $file) {
                unlink($file) or warn "Could not remove $file: $!";
            }
        }
        print "Removed $cons_count refiner consensus intermediate files\n";
    }
    
    # Report cleanup summary
    my $total_removed = $family_count + $log_count + $cons_count;
    if ($total_removed > 0) {
        print "Cleanup completed: removed $total_removed temporary files\n";
    } else {
        print "No temporary files found to clean up\n";
    }
}
